<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="main.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
    <title>Document</title>
</head>
<body>
    <title>Project Proposal</title>
    <h1>Enhancing Recycling with Object Detection Technology</h1>
    <h3>Team Members : Ashwin Shanmugasundaram, Avanthika Rajesh, Iffat Khatib</h3>
        <h2 class="heading">Problem Statement</h2>
            <p class="content"> The importance of effective waste segregation in facilitating the management of waste in an environmentally friendly manner cannot be overemphasized. This is, however, a very time consuming, tedious and error-primed manual process. With the increase in the amount of the waste all over the world, the lack of automation to this process leads to improper waste disposal and increased landfills that deteriorate the environment and waste valuable resources. There is an urgent requirement of a waste detection and classification system which is efficient and can operate in real time to help in achieving these segregation goals. This project seeks to overcome this problem by implementing an AI based waste detection system using YOLOv8 which is an advanced object detection model to detect recyclable, non-recyclable and hazardous wastes in real time through a webcam. The proposed system will improve waste management in a variety of environments including open parks, recycling stations, households, etc., thereby improving the environmentally friendly practices of waste disposal.</p>
        <h2 class="heading">Approach</h2>
            <p class="sub">Model Selection for Object Detection</p>
                <p class="sub_content">Pre-trained Models: Leverage state-of-the-art object detection models pre-trained on large datasets. Common model we are going to use will be  YOLO V8  (You Only Look Once), Fast real-time object detection.
                </p>
            <p class="sub"> Feature Extraction and Training</p>
                <p class="sub_content">Use a pre-trained backbone network (e.g., ResNet, EfficientNet) to extract features from waste images. Transfer learning helps reduce training time and achieves better results with less data.
                </p>
                <p class="sub_content">
                    Define anchor boxes that are appropriate for the different sizes of waste items in the images. This helps the object detector better localize items.
                </p>
            <p class="sub">Model Evaluation</p>
                <p class="sub_content">
                    Use metrics like Mean Average Precision (mAP), Intersection over Union (IoU), Precision, and Recall to evaluate model performance
                </p>
                <p class="sub_content">
                    Test the model in real-time scenarios to ensure the object detection and classification system works effectively in waste sorting facilities.
                </p>
            <p class="sub">Tools and Frameworks</p>
                <p class="sub_content">
                    •   Deep Learning Frameworks: TensorFlow or Keras. 
                </p>
                <p class="sub_content">
                    •	Object Detection Libraries: OpenCV for image processing 
                </p>
                <p class="sub_content">
                    •	Hardware: GPUs for training
                </p>
        <h2 class="heading">Plans for experiments</h2>
            <p class="content">
                So in order to conduct the experiment we will be collecting data from TrashNet as well as getting some custom data ourselves in order to train the model well with a variety of trash like plastic, wet garbage, electronic items, paper from trash bins, streets, etc. We will train the model on real-time data so that we achieve great results in real-world scenarios
            </p>
            <p class="content">
                The model will first capture an image using and then identify the object from the image and then label it as trash, to implement this we are going to use Labellmg an image annotation tool. Using this label we get a percentage that measures how accurately an item is identified.
            </p>
            <p class="content">
                For enhanced and real-time object detection we use YOLO v8 which we will fine-tune with data from TrashNet and our data. Using this it will proceed to make more descriptive classifications such as Recyclable, Non recyclable, and Hazardous waste.
            </p>
            <p class="content">
                To assess the overall performance of the model mean Average Precision (mAP) is being used along with Intersection over Union (IoU), Precision, and Recall. And the deep learning framework that will be used is either TensorFlow or Keras. For the entire image processing and segmentation, OpenCv is being used in our project.
            </p>
        <h2 class="heading">Dataset</h2>
            <p class="content"><a href="https://www.kaggle.com/datasets/feyzazkefe/trashnet" , target="_blank">Dataset link</a></p>
            <p class="content">The TrashNet dataset will be associated with crowdsourced images of ignoring objects' household waste in order to guarantee high-quality and realistic visible images. TrashNet is a publicly available dataset with more than 2500 images depicting common waste categories such as plastic, paper, glass, metal and cardboard, which are accompanied by annotations for their proper bounding box use. The images from this dataset will form the first step in training the object detection model as it is generic whereas most images contain waste of much variety. This was much possible because there are a lot of databases in which people can access these resources. However, TrashNet has some limitations including coverage of a few waste types and factors that do not extend beyond the picture such as illumination and composition factors which vary in specific locations.</p>
            <p class="content">These documents highlight some deficiencies of the model by cross-using other images in addition to TrashNet to capture the differences. In order to diversify the waste images under consideration, we will also take photographs of related objects in real places such as recycling plants, domestic bins, or other waste sorting facilities. After image collection will be complete, we will spend some time carefully labeling the images with bounding boxes and labels using programs like LabelImg or VoTT which assure that the unintended inconsistency with the TrashNet’s labeling practices remains absent.By combining the TrashNet dataset with our custom images, we aim to create a balanced and diverse dataset that captures a wide range of waste objects and scenarios. This approach will help the model handle real-world challenges like object occlusion, varying sizes, and mixed waste types, ultimately making the waste sorting system more reliable and effective in real-time applications</p>
        <h2 class="heading">Data Collection</h2>
            <p class="content">For this project, we will add our own data points by manually collecting images of waste items. The dataset will include three categories such as
            </p>
            <p class="content">•   Recyclable</p>
            <p class="content">•   non-recyclable</p>
            <p class="content">•   hazardous waste</p>
            <p class="sub">The procedure for collecting data involves the following steps:</p>
                <p class="content">
                    <p1>Identifying Waste Items: </p1> We will gather a variety of waste items commonly found in households, public spaces, and workplaces. These items will be categorized as recyclable (e.g., plastic bottles, paper), non-recyclable (e.g., food waste), and hazardous (e.g., batteries, chemicals).
                </p>
                <p class="content">
                    <p1>Capturing Images: </p1> Using a high-resolution camera, we will take multiple pictures of each item from different angles and lighting conditions to ensure a clear dataset. The items will be placed in different environments and backgrounds to make it difficult for the system to identify.
                </p>
                <p class="content">
                    <p1>Labeling: </p1> After collecting the images, we will manually label each item using a tool such as LabelImg to create boxes around the waste items. Each item will be labeled according to its category (recyclable, non-recyclable, or hazardous).
                </p>
                <p class="content">
                    <p1>Dataset Structure: </p1> The dataset will be organized into three folders which are recyclable, non-recyclable, and hazardous with each folder containing labeled images corresponding to its category. This structured dataset will be used to train the YOLOv8 object detection model.
                </p>
        <h2 class="heading">Code Implementation Plan</h2>
            <p class="content">
                For the Object Detection for Waste Sorting project, we will leverage existing code and frameworks to accelerate development and ensure robust performance. Specifically, we will borrow pre-trained models from well-established deep learning libraries like TensorFlow or PyTorch, which offer access to cutting-edge object detection architectures such as YOLO (You Only Look Once).These models are pre-trained on large datasets like COCO, giving us a strong starting point for transfer learning. By fine-tuning these models on our specific waste sorting dataset (TrashNet + custom images), we can adapt them to recognize waste categories more effectively.
            </p>
            <p class="content">
                In addition to using  pre-trained models and existing frameworks, we will also write custom code to handle key parts of the project. Specifically, we will develop custom scripts to integrate the TrashNet dataset with our custom-collected images, Furthermore, the training loop for fine-tuning pre-trained models will be written from scratch, which includes setting up custom loss functions, optimizers, and learning rate schedules. We will also implement callbacks like early stopping to monitor model performance and avoid overfitting. This custom code will ensure that the training process is optimized for our specific waste sorting application and that the model integrates seamlessly with the combined dataset.
            </p>
        <h2 class="heading">List of experiments</h2>
            <p class="content">1.     Collect a variety of waste items</p>
            <p class="content">2.     Real-time image capturing of waste</p>
            <p class="content">3.     Image Labelling using LabelImg</p>
            <p class="content">4.     Object detection using YOLOv8</p>
        <h2 class="heading">Expected Outcomes of the Project</h2>
            <p class="content">
                It is expected that the model can tell apart the trash by understanding it’s minute features regardless of object occlusion, varying sizes, mixed waste types, and it’s position in the image with any background, and label them in the image precisely. Subsequently, from all of the real-time images, once the waste is identified it should further classify the waste, particularly as recyclable waste, non-recyclable waste, or hazardous waste to help in the segregation process in various environments with accuracy and make the waste management process quick and efficient whilst avoiding cross contamination.
            </p>
        <h2 class="heading">Uncertainties in the Potential Result</h2>
            <p class="content">
                Many factors like an image being blurred, grainy, lightning, and shadow etc can affect the potential outcomes. Additionally, instances like when the item is packed in such a way that the item cannot be recognized precisely can give a bad result. One prevailing case can be when the image is not well captured, concerning the wrong angle can give us only a part of the object, making it difficult to detect and classify.
            </p>
            <p class="content">
                Another uncertain outcome is when the model gets confused when it has to do classification in an instance where the trash is deformed and where the shape or features are not clear. Moreover, if the model is trained using limited data and is more focused on common items, it can be a struggle to recognize uncommon kinds of trash.
            </p>
            <p class="content">
                In a scenario where classification is done incorrectly where the model cannot decide between recyclable, non-recyclable, and hazardous trash, if it labels a hazardous item otherwise it can cause major safety issues.
            </p>
        </body>
</html>